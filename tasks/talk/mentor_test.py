import os
import yaml
import json
from openai import OpenAI


# ================= å·¥å…·ï¼šè¯»å–é…ç½® =================
def load_config(config_path="config.yaml"):
    try:
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°åŒçº§ç›®å½•ä¸‹çš„ yaml
        base_dir = os.path.dirname(os.path.abspath(__file__))
        abs_path = os.path.join(base_dir, config_path)

        with open(abs_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None


# ================= æ ¸å¿ƒï¼šå¯¼å¸ˆç±» =================
class ProjectMentor:
    def __init__(self, config, analysis_result):
        """
        Args:
            config: å®Œæ•´çš„é…ç½®å­—å…¸ (ä» yaml è¯»å–)
            analysis_result: Step 1 çš„ JSON æ•°æ®
        """
        # 1. ç›´æ¥ä» config['mentor'] è¯»å–æ‰€æœ‰å‚æ•°
        mentor_cfg = config["mentor"]

        self.client = OpenAI(
            api_key=mentor_cfg["api_key"],
            base_url=mentor_cfg["base_url"],
            timeout=120
        )
        self.model = mentor_cfg["model_name"]

        # 2. ã€å…³é”®ã€‘ä» YAML ä¸­è·å– Prompt
        base_prompt = mentor_cfg["prompt"]

        # 3. å°†è§†è§‰è¯†åˆ«ç»“æœæ³¨å…¥åˆ° Prompt ä¸­
        context_str = json.dumps(analysis_result, ensure_ascii=False, indent=2)

        full_system_prompt = f"""
        {base_prompt}

        ã€å½“å‰è¾“å…¥çš„è§†è§‰åˆ†ææ•°æ® (Context)ã€‘
        {context_str}
        """

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self.history = [
            {"role": "system", "content": full_system_prompt}
        ]

    def chat(self, user_input=None):
        """
        å‘é€å¯¹è¯è¯·æ±‚
        """
        # å¦‚æœæœ‰è¾“å…¥ï¼ŒåŠ å…¥å†å²ï¼›å¦‚æœæ˜¯ Noneï¼Œè¯´æ˜æ˜¯ç¬¬ä¸€è½®è‡ªåŠ¨è§¦å‘
        if user_input:
            self.history.append({"role": "user", "content": user_input})
        else:
            self.history.append({"role": "user", "content": "è¯·æ ¹æ®åˆ†ææ•°æ®ï¼Œç›´æ¥ç”Ÿæˆæ–¹æ¡ˆã€‚"})

        try:
            print("ğŸ¤– å¯¼å¸ˆæ­£åœ¨æ€è€ƒ...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.history,
                temperature=0.2  # è¿™é‡Œä¹Ÿå¯ä»¥ä» config è¯»å–ï¼Œçœ‹ä½ éœ€æ±‚
            )

            reply = response.choices[0].message.content

            # è®°ä½ AI çš„å›å¤
            self.history.append({"role": "assistant", "content": reply})

            return reply

        except Exception as e:
            return f"âŒ æ¥å£è°ƒç”¨å‡ºé”™: {e}"


# ================= æœ¬åœ°æµ‹è¯•å…¥å£ =================

if __name__ == "__main__":
    # 1. è¯»å–çœŸå®çš„ config.yaml
    config = load_config()

    if config:
        # 2. å‡†å¤‡ä¸€ä»½ Step 1 çš„å‡æ•°æ® (å› ä¸ºè¿™é‡Œåªæµ‹ Step 2)
        # å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™ä¸ªæ•°æ®æ˜¯ä¸Šä¸€ä¸ªæ¥å£ä¼ è¿‡æ¥çš„
        step1_result_mock = {
            "project_title": "æ™ºèƒ½é¿éšœå°è½¦",
            "visual_components": ["è½¦è½®", "è¶…å£°æ³¢ä¼ æ„Ÿå™¨", "åº•ç›˜"],
            "user_intent_analysis": "åšä¸€ä¸ªèƒ½è‡ªåŠ¨èº²é¿éšœç¢ç‰©çš„å°è½¦"
        }

        print("=== âœ… é…ç½®åŠ è½½æˆåŠŸï¼Œå¼€å§‹æµ‹è¯•å¯¼å¸ˆæ¨¡å— ===")

        # 3. åˆå§‹åŒ–
        mentor = ProjectMentor(config, step1_result_mock)

        # 4. ç¬¬ä¸€è½®ï¼šè‡ªåŠ¨ç”Ÿæˆæ–¹æ¡ˆ
        initial_plan = mentor.chat()
        print(f"\nğŸ“ [åˆå§‹æ–¹æ¡ˆ]:\n{initial_plan}\n")

        # 5. è¿›å…¥æ‰‹åŠ¨å¯¹è¯æµ‹è¯•
        while True:
            user_input = input("ğŸ‘¤ å­¦ç”Ÿ (è¾“å…¥ q é€€å‡º): ")
            if user_input.lower() == 'q':
                break

            reply = mentor.chat(user_input)
            print(f"\nğŸ“ [å¯¼å¸ˆå›å¤]:\n{reply}\n")
    else:
        print("è¯·æ£€æŸ¥ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨ config.yaml")